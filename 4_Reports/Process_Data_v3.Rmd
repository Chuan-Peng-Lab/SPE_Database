---
title: "Process_Data_v3"
author: "czx"
date: "`r Sys.Date()`"
output: html_document
---

# Process Coding
## Loading package
```{r Package, warning = FALSE,message = FALSE}
## 加载必要的 R 包
library(tidyr)
library(dplyr)
library(stringr)
library(effsize)
library(here)
library(pwr)
library(ggplot2)
```

# Read csv (区分公开和未公开) [包含没有Trial记录的]
```{r}
library(dplyr)
library(readr)

## 设置数据路径
dataPath <- "../1_Clean_Data"
data_files <- list.files(path = dataPath, pattern = "\\.csv$", full.names = TRUE, recursive = TRUE)

## 需要排除的文件夹
exclude_folders <- c("Bukowski_2021_AP", "Golubickis_2021_AP", 
                     "Hobbs_2023_PM", "Mcivor_2020_EJN", 
                     "Orellana-Corrales_2021_EP", "Svensson_2021_PR", 
                     "Wang_2016_EPHPP")

## 过滤掉不需要的文件
data_files <- data_files[!grepl(paste(exclude_folders, collapse = "|"), data_files)]

## 预分配存储变量（列表存储数据）
results_list <- list()

## 计数器
counter <- 1

## 读取 CSV 文件并处理数据
for (i in seq_along(data_files)) {
  file_name <- basename(data_files[i])  # 提取文件名（假设文件名代表文章名称）
  
  Data <- read_csv(data_files[i], show_col_types = FALSE) %>%
    mutate(across(where(is.character), as.character))  # 确保字符变量类型一致
  
  # 确保数据包含所需变量
  if (all(c("RT_ms", "ACC", "Standarlized_Identity", "Subject", "Matching") %in% names(Data))) {
    
    # 生成唯一标识每篇文章的 Subject ID，并添加 Source 变量
    Data <- Data %>%
      mutate(
        Subject = paste0(file_name, "_", Subject),
        Source = file_name  # **新增变量，标记来源文章**
      )
    
    # 过滤 RT 在合理范围内的行
    Data <- Data %>%
      filter(RT_ms > 10 & RT_ms < 5000, ACC %in% c(0, 1))  # 过滤异常值

    # **存入列表**
    results_list[[counter]] <- Data %>%
      select(Source, Subject, Matching, Standarlized_Identity, RT_ms, ACC)  # **保留 Source 变量**
    
    counter <- counter + 1
  }
  print(paste('完成数据集', i, '处理'))
}

# **合并所有数据**
results <- bind_rows(results_list)

# **检查合并后的数据**
print("数据处理完成，已存入 `results` 变量")

# **输出数据到 CSV**
write.csv(results, "Processed_Data.csv", row.names = FALSE)
```

# 论文数量、实验数量、被试数
```{r}
library(dplyr)
library(readr)
library(stringr)

# 读取已处理的数据
data <- read_csv("Processed_Data.csv", show_col_types = FALSE)

# 提取文章名称（不包含实验部分）
data <- data %>%
  mutate(Article = str_extract(Source, "^[^_]+_\\d{4}_[^_]+")) %>%  # 提取 作者_年份_期刊
  mutate(Experiment = str_extract(Source, "Exp\\d+")) %>%  # 提取实验编号
  mutate(Subject_ID = str_extract(Subject, "[^_]+$"))  # 提取被试编号

# 统计文章、实验、被试数量
summary_table <- data %>%
  group_by(Article, Experiment) %>%
  summarise(Num_Subjects = n_distinct(Subject_ID), .groups = "drop") %>%
  arrange(Article, Experiment)

# 统计每篇文章的实验数
article_summary <- summary_table %>%
  group_by(Article) %>%
  summarise(Num_Experiments = n_distinct(Experiment), Total_Subjects = sum(Num_Subjects), .groups = "drop")

# 输出结果
write.csv(summary_table, "Experiment_Summary.csv", row.names = FALSE)
write.csv(article_summary, "Article_Summary.csv", row.names = FALSE)
```

## Pic1
```{r}
library(ggplot2)
library(dplyr)
library(tidyr)
library(Hmisc)
library(plyr)
library(RColorBrewer)
library(reshape2)

# 读取数据
data <- read.csv("Processed_Data.csv")

# 重新命名列以匹配需求
colnames(data) <- c("rt_self", "rt_close", "rt_stranger", "rt_non_person", "rt_acquaintance", 
                    "cohens_d_self_close", "cohens_d_self_stranger", "cohens_d_self_non_person", "cohens_d_self_acquaintance")

# 计算 RT 差值
data$SA_RT <- data$rt_self - data$rt_acquaintance
data$SC_RT <- data$rt_self - data$rt_close
data$SS_RT <- data$rt_self - data$rt_stranger
data$SN_RT <- data$rt_self - data$rt_non_person

# 定义 geom_flat_violin
"%||%" <- function(a, b) { if (!is.null(a)) a else b }

geom_flat_violin <- function(mapping = NULL, data = NULL, stat = "ydensity",
                             position = "dodge", trim = TRUE, scale = "area",
                             show.legend = NA, inherit.aes = TRUE, ...) {
  layer(
    data = data,
    mapping = mapping,
    stat = stat,
    geom = GeomFlatViolin,
    position = position,
    show.legend = show.legend,
    inherit.aes = inherit.aes,
    params = list(
      trim = trim,
      scale = scale,
      ...
    )
  )
}

GeomFlatViolin <- ggproto("GeomFlatViolin", Geom,
          setup_data = function(data, params) {
            data$width <- data$width %||%
              params$width %||% (resolution(data$x, FALSE) * 0.9)
            
            data %>%
              group_by(group) %>%
              mutate(ymin = min(y),
                     ymax = max(y),
                     xmin = x,
                     xmax = x + width / 2)
          },
          draw_group = function(data, panel_scales, coord) {
            data <- transform(data, xminv = x,
                              xmaxv = x + violinwidth * (xmax - x))
            newdata <- rbind(plyr::arrange(transform(data, x = xminv), y),
                             plyr::arrange(transform(data, x = xmaxv), -y))
            newdata <- rbind(newdata, newdata[1,])
            ggplot2:::ggname("geom_flat_violin", GeomPolygon$draw_panel(newdata, panel_scales, coord))
          },
          draw_key = draw_key_polygon,
          default_aes = aes(weight = 1, colour = "grey20", fill = "white", size = 0.5,
                            alpha = NA, linetype = "solid"),
          required_aes = c("x", "y")
)

raincloud_theme <- theme(
  text = element_text(size = 10),
  axis.title.x = element_text(size = 16),
  axis.title.y = element_text(size = 16),
  axis.text = element_text(size = 14),
  axis.text.x = element_text(angle = 45, vjust = 0.5),
  legend.title = element_text(size = 16),
  legend.text = element_text(size = 16),
  legend.position = "right",
  plot.title = element_text(lineheight = .8, face = "bold", size = 16),
  panel.border = element_blank(),
  panel.grid.minor = element_blank(),
  panel.grid.major = element_blank(),
  axis.line.x = element_line(colour = 'black', size = 0.5, linetype = 'solid'),
  axis.line.y = element_line(colour = 'black', size = 0.5, linetype = 'solid')
)

# 画图函数
generate_plot <- function(x_var, y_var, x_label, y_label, title) {
  ggplot(data, aes_string(x = x_var, y = y_var)) +
    geom_point(color = "blue", alpha = 0.6) +
    geom_boxplot(width = 0.2, outlier.shape = NA) +
    geom_flat_violin(aes(fill = ..density..), scale = "width", trim = FALSE, alpha = 0.5) +
    geom_smooth(method = "lm", color = "red", se = TRUE) +
    theme_minimal() +
    raincloud_theme +
    labs(x = x_label, y = y_label, title = title)
}

# 绘制四个图
p1.1 <- generate_plot("SA_RT", "cohens_d_self_acquaintance", "SA_RT", "Cohen's d (Self - Acquaintance)", "P1.1: RT vs. Cohen's d (Self - Acquaintance)")
p1.2 <- generate_plot("SC_RT", "cohens_d_self_close", "SC_RT", "Cohen's d (Self - Close)", "P1.2: RT vs. Cohen's d (Self - Close)")
p1.3 <- generate_plot("SS_RT", "cohens_d_self_stranger", "SS_RT", "Cohen's d (Self - Stranger)", "P1.3: RT vs. Cohen's d (Self - Stranger)")
p1.4 <- generate_plot("SN_RT", "cohens_d_self_non_person", "SN_RT", "Cohen's d (Self - Non-Person)", "P1.4: RT vs. Cohen's d (Self - Non-Person)")

# 显示所有图形
library(gridExtra)
grid.arrange(p1.1, p1.2, p1.3, p1.4, ncol = 2)
```

# Copute SDE
## Read csv (区分公开和未公开) [只包含有Trial记录的]
```{r}
library(dplyr)
library(readr)

## 设置数据路径
dataPath <- "../1_Clean_Data"
data_files <- list.files(path = dataPath, pattern = "\\.csv$", full.names = TRUE, recursive = TRUE)

## 需要排除的文件夹
exclude_folders <- c("Bukowski_2021_AP", "Golubickis_2021_AP", 
                     "Hobbs_2023_PM", "Mcivor_2020_EJN", 
                     "Orellana-Corrales_2021_EP", "Svensson_2021_PR", 
                     "Wang_2016_EPHPP")

## 过滤掉不需要的文件
data_files <- data_files[!grepl(paste(exclude_folders, collapse = "|"), data_files)]

## 预分配存储变量（列表存储数据）
results_list <- list()

## 计数器
counter <- 1

## 读取 CSV 文件并处理数据
for (i in seq_along(data_files)) {
  file_name <- basename(data_files[i])  # 提取文件名（假设文件名代表文章名称）
  
  Data <- read_csv(data_files[i], show_col_types = FALSE) %>%
    mutate(across(where(is.character), as.character))  # 确保字符变量类型一致
  
  # 确保数据包含所需变量
  if (all(c("RT_ms", "ACC", "Standarlized_Identity", "Subject", "Matching", "Trial") %in% names(Data))) {
    
    # 生成唯一标识每篇文章的 Subject ID，并添加 Source 变量
    Data <- Data %>%
      mutate(
        Subject = paste0(file_name, "_", Subject),
        Source = file_name  # **新增变量，标记来源文章**
      )
    
    # 过滤 RT 在合理范围内的行
    Data <- Data %>%
      filter(RT_ms > 10 & RT_ms < 5000, ACC %in% c(0, 1))  # 过滤异常值

    # **存入列表**
    results_list[[counter]] <- Data %>%
      select(Source, Subject, Trial, Matching, Standarlized_Identity, RT_ms, ACC)  # **保留 Source 变量**
    
    counter <- counter + 1
  }
  print(paste('完成数据集', i, '处理'))
}

# **合并所有数据**
results <- bind_rows(results_list)

# **检查合并后的数据**
print("数据处理完成，已存入 `results` 变量")

# **输出数据到 CSV**
write.csv(results, "Processed_Data_for_SDE.csv", row.names = FALSE)
```

```{r}
library(dplyr)
library(readr)

## 设置数据路径
dataPath <- "../1_Clean_Data"
data_files <- list.files(path = dataPath, pattern = "\\.csv$", full.names = TRUE, recursive = TRUE)

## 需要排除的文件夹
exclude_folders <- c("Bukowski_2021_AP", "Golubickis_2021_AP", 
                     "Hobbs_2023_PM", "Mcivor_2020_EJN", 
                     "Orellana-Corrales_2021_EP", "Svensson_2021_PR", 
                     "Wang_2016_EPHPP")

## 过滤掉不需要的文件
data_files <- data_files[!grepl(paste(exclude_folders, collapse = "|"), data_files)]

## 预分配存储变量（列表存储数据）
results_list <- list()

## 计数器
counter <- 1

## 读取 CSV 文件并处理数据
for (i in seq_along(data_files)) {
  file_name <- basename(data_files[i])  # 提取文件名（假设文件名代表文章名称）
  
  Data <- read_csv(data_files[i], show_col_types = FALSE) %>%
    mutate(across(where(is.character), as.character))  # 确保字符变量类型一致
  
  # 确保数据包含所需变量
  if (all(c("RT_ms", "ACC", "Standarlized_Identity", "Subject", "Matching", "Block", "Trial","Gender") %in% names(Data))) {
    
    # 生成唯一标识每篇文章的 Subject ID，并添加 Source 变量
    Data <- Data %>%
      mutate(
        Subject = paste0(file_name, "_", Subject),
        Source = file_name  # **新增变量，标记来源文章**
      )
    
    # 过滤 RT 在合理范围内的行
    Data <- Data %>%
      filter(RT_ms > 10 & RT_ms < 5000, ACC %in% c(0, 1))  # 过滤异常值

    # **存入列表**
    results_list[[counter]] <- Data %>%
      select(Source, Subject, Block, Trial, Matching, Standarlized_Identity, RT_ms, ACC)  # **保留 Source 变量**
    
    counter <- counter + 1
  }
  print(paste('完成数据集', i, '处理'))
}

# **合并所有数据**
results <- bind_rows(results_list)

# **检查合并后的数据**
print("数据处理完成，已存入 `results` 变量")

# **输出数据到 CSV**
write.csv(results, "Processed_Data.csv", row.names = FALSE)
```

## Test01
```{r}
library(dplyr)
library(lme4)  # 用于LMM
library(lmerTest)  # 提供p值（可选）

# 假设你的数据已加载到 `results` 中
# 如果没有，先运行你的原始代码生成 `results`

# 1. 按Subject和Block排序，并生成lag变量
data_seq <- results %>%
  arrange(Subject, Block, Trial) %>%
  group_by(Subject, Block) %>%  # 在每个Subject和Block内操作
  mutate(
    Lag1_Identity = lag(Standarlized_Identity, 1),  # 前1次
    Lag2_Identity = lag(Standarlized_Identity, 2),  # 前2次
    Lag3_Identity = lag(Standarlized_Identity, 3),  # 前3次
    Lag4_Identity = lag(Standarlized_Identity, 4),  # 前4次
    Lag5_Identity = lag(Standarlized_Identity, 5),  # 前5次
    Lag6_Identity = lag(Standarlized_Identity, 6),  # 前6次
    Lag7_Identity = lag(Standarlized_Identity, 7)   # 前7次
  ) %>%
  ungroup()

# 2. 移除开头没有完整lag数据的行
data_seq_clean <- data_seq %>%
  filter(!is.na(Lag7_Identity))  # 确保所有lag变量都非NA

# 3. 检查数据
print("序列位置效应数据已生成，以下是前几行：")
print(head(data_seq_clean))

# 4. 建立LMM模型分析RT
# 固定效应：当前Identity + 前7次Identity
# 随机效应：Subject
rt_lmm <- lmer(RT_ms ~ Standarlized_Identity + Lag1_Identity + Lag2_Identity + 
               Lag3_Identity + Lag4_Identity + Lag5_Identity + Lag6_Identity + 
               Lag7_Identity + (1 | Subject), 
               data = data_seq_clean)

# 5. 查看模型结果
summary(rt_lmm)

# 6. （可选）保存模型结果到文件
sink("RT_LMM_Summary.txt")
print(summary(rt_lmm))
sink()

# 7. 保存处理后的数据
write.csv(data_seq_clean, "Sequence_Effect_Data.csv", row.names = FALSE)
```

## Test02
```{r}
# 加载必要的库
library(dplyr)
library(ggplot2)
library(readr)

# 读取数据
data <- read_csv("Processed_Data_for_SDE.csv")

# 按 Source、Subject 和 Trial 排序
data <- data %>%
  arrange(Source, Subject, Trial) %>%
  group_by(Source, Subject) %>%
  mutate(
    Prev_Matching = lag(Matching),  # 计算上一试次的Matching
    Prev_ACC = lag(ACC),            # 计算上一试次的正确率
    Prev_RT_ms = lag(RT_ms)         # 计算上一试次的反应时
  ) %>%
  ungroup()

# 计算上一试次的Matching对当前试次ACC的影响
acc_model <- glm(ACC ~ Prev_Matching, data = data, family = binomial)
summary(acc_model)

# 计算上一试次的Matching对当前试次RT_ms的影响
rt_model <- lm(RT_ms ~ Prev_Matching, data = data)
summary(rt_model)

# 可视化上一试次Matching对当前试次RT_ms的影响
ggplot(data, aes(x = Prev_Matching, y = RT_ms)) +
  geom_boxplot() +
  labs(title = "Previous Matching Condition and Current RT_ms",
       x = "Previous Matching Condition",
       y = "Reaction Time (ms)") +
  theme_minimal()

```

## Test03
```{r}
# 加载必要的包
library(tidyverse)
library(lme4)
library(lmerTest)
library(ggplot2)

# 读取数据
data <- read_csv("Processed_Data_for_SDE.csv")

# 按 Source（实验来源）、Subject（被试）、Trial（试次）排序，确保顺序正确
data <- data %>% arrange(Source, Subject, Trial)

# 计算 Lag-1 变量（上一试次的 Matching 条件）
data <- data %>%
  group_by(Source, Subject) %>%
  mutate(Prev_Matching = lag(Matching)) %>%
  ungroup()

# 移除首个试次（因为没有上一试次）
data <- na.omit(data)

# 确保 Matching 和 Prev_Matching 变量是因子变量
data$Matching <- as.factor(data$Matching)
data$Prev_Matching <- as.factor(data$Prev_Matching)
```

```{r}
# 逻辑回归模型（因变量：ACC，预测变量：Prev_Matching）
acc_model <- glmer(ACC ~ Prev_Matching + (1 | Subject) + (1 | Source),
                   family = binomial, data = data)

# 输出结果
summary(acc_model)
```

```{r}
# 计算不同 Lag（1~7） 条件下的相关系数
compute_autocorr <- function(data, max_lag = 7) {
  autocorr_results <- data.frame(Lag = integer(), Beta = numeric(), SE = numeric(), P_Value = numeric())
  
  for (lag in 1:max_lag) {
    data <- data %>%
      group_by(Source, Subject) %>%
      mutate(Prev_Matching = lag(Matching, lag)) %>%
      ungroup() %>%
      na.omit()
    
    # 计算混合模型
    model <- glmer(ACC ~ Prev_Matching + (1 | Subject) + (1 | Source), family = binomial, data = data)
    
    # 提取 β 系数、标准误和 p 值
    beta <- summary(model)$coefficients["Prev_MatchingNonmatching", "Estimate"]
    se <- summary(model)$coefficients["Prev_MatchingNonmatching", "Std. Error"]
    p_value <- summary(model)$coefficients["Prev_MatchingNonmatching", "Pr(>|z|)"]
    
    # 存储结果
    autocorr_results <- rbind(autocorr_results, data.frame(Lag = lag, Beta = beta, SE = se, P_Value = p_value))
  }
  
  return(autocorr_results)
}

# 计算 Lag-1 ~ Lag-7 的自相关
autocorr_results <- compute_autocorr(data, max_lag = 7)

# 查看结果
print(autocorr_results)
```

```{r}
# 画图（仿照 Rahnev 的 NHB 图）
ggplot(autocorr_results, aes(x = Lag, y = Beta)) +
  geom_point(size = 4, color = "blue") +                        # 画点
  geom_errorbar(aes(ymin = Beta - SE, ymax = Beta + SE),        # 误差条
                width = 0.2, color = "blue") +
  geom_line(size = 1, color = "blue") +                         # 连接线
  theme_minimal(base_size = 16) +
  labs(title = "Serial Dependence in Accuracy (Lag-1 to Lag-7)",
       x = "Lag (Previous Trial)",
       y = "Autocorrelation (Beta ± SEM)") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

```

## Test04
```{r}
# 加载必要的包
library(tidyverse)
library(lme4)
library(lmerTest)
library(broom.mixed)

# 读取数据
data <- read_csv("Processed_Data_for_SDE.csv")

# 预处理：生成lag变量
data_preprocessed <- data %>%
  arrange(Source, Subject, Trial) %>%
  group_by(Subject) %>%
  mutate(
    Lag1_Matching = lag(Matching),
    Lag2_Matching = lag(Matching, 2),
    Lag3_Matching = lag(Matching, 3),
    Lag4_Matching = lag(Matching, 4),
    Lag5_Matching = lag(Matching, 5),
    Lag6_Matching = lag(Matching, 6),
    Lag7_Matching = lag(Matching, 7)
  ) %>%
  ungroup()

# 初始化结果存储
results <- tibble()

# 分析不同lag的效应
for (lag_num in 1:7) {
  # 选择对应的lag变量
  lag_var <- paste0("Lag", lag_num, "_Matching")
  
  # 过滤有效数据
  temp_data <- data_preprocessed %>%
    filter(!is.na(!!sym(lag_var))) %>%
    rename(Current_Matching = Matching)
  
  # 运行混合效应模型（以反应时为例）
  model <- lmer(
    RT_ms ~ !!sym(lag_var) + (1 | Subject) + (1 | Source),
    data = temp_data
  )
  
  # 提取结果
  summ <- summary(model)
  coeffs <- summ$coefficients
  
  # 存储结果
  results <- results %>% bind_rows(
    tibble(
      Lag = lag_num,
      Beta = coeffs[2, "Estimate"],
      SE = coeffs[2, "Std. Error"],
      t = coeffs[2, "t value"],
      p = coeffs[2, "Pr(>|t|)"]
    )
  )
}

# 可视化
ggplot(results, aes(x = Lag, y = Beta)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray60") +
  geom_line(color = "steelblue") +
  geom_point(size = 3, color = "steelblue") +
  geom_errorbar(aes(ymin = Beta - SE, ymax = Beta + SE), 
                width = 0.2, color = "steelblue") +
  geom_text(aes(label = ifelse(p < 0.001, "***", 
                             ifelse(p < 0.01, "**",
                                    ifelse(p < 0.05, "*", "")))),
            vjust = -0.5, size = 5) +
  scale_x_continuous(breaks = 1:7) +
  labs(x = "Lag", 
       y = "β Coefficient",
       title = "Serial Dependence in Reaction Time",
       subtitle = "Effect of Previous Trial's Matching Condition on Current Trial RT") +
  theme_minimal(base_size = 14) +
  theme(
    panel.grid.minor = element_blank(),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5)
  )
```





