---
title: "Process_Data_v3"
author: "czx"
date: "`r Sys.Date()`"
output: html_document
---

# Process Coding
## Loading package
```{r Package, warning = FALSE,message = FALSE}
## 加载必要的 R 包
library(tidyr)
library(dplyr)
library(stringr)
library(effsize)
library(here)
library(pwr)
library(ggplot2)
```

## Set data path 
```{r}
dataPath = "../1_Clean_Data"
data_files <- list.files(path = dataPath, pattern = "\\.csv$", full.names = TRUE, recursive = TRUE)
```

## Read csv
```{r}
## 预分配存储变量（使用列表存储数据，避免 `assign()`）
results_list <- list()

## 读取 CSV 文件并处理数据
counter <- 1
for (i in seq_along(data_files)) {
  Data <- read.csv(data_files[i], fileEncoding = "UTF-8-BOM")
  
  # 确保数据包含必要的变量
  if (all(c("RT_ms", "Standarlized_Identity", "Subject", "Matching") %in% names(Data))) {
    
    # 获取当前数据集包含的 Identity（自动筛选）
    available_identities <- unique(Data$Standarlized_Identity)
    Data$Subject <- paste0(basename(data_files[i]), "_", Data$Subject)

    # 获取当前数据集的所有被试
    subs <- unique(Data$Subject)
    
    for (sub in subs) {
      temp <- Data %>%
        filter(Subject == sub) %>%
        filter(RT_ms > 10 & RT_ms < 5000)  # 过滤异常反应时
      
      for (match_condition in c("Matching", "Nonmatching")) {
        temp_match <- temp %>% filter(Matching == match_condition)
        
        # 计算 Self 的 RT
        rt_self <- if ("Self" %in% available_identities) {
          mean(temp_match$RT_ms[temp_match$Standarlized_Identity == "Self"], na.rm = TRUE)
        } else { NA }
        
        # 存储当前被试的结果
        temp_results <- list(
          Subject = sub,
          Matching = match_condition,
          rt_self = rt_self
        )
        
        # 计算各个 Identity 的 RT 和 Cohen’s d
        for (identity in c("Close", "Stranger", "NonPerson", "Acquaintance")) {
          rt_identity <- if (identity %in% available_identities) {
            mean(temp_match$RT_ms[temp_match$Standarlized_Identity == identity], na.rm = TRUE)
          } else { NA }
          
          # 计算 Cohen’s d
          if (!is.na(rt_self) & !is.na(rt_identity)) {
            pooled_sd <- sqrt((sd(temp_match$RT_ms[temp_match$Standarlized_Identity == "Self"], na.rm = TRUE)^2 + 
                               sd(temp_match$RT_ms[temp_match$Standarlized_Identity == identity], na.rm = TRUE)^2) / 2)
            cohens_d <- (rt_self - rt_identity) / pooled_sd
          } else {
            cohens_d <- NA
          }
          
          temp_results[[paste0("rt_", tolower(identity))]] <- rt_identity
          temp_results[[paste0("cohens_d_self_", tolower(identity))]] <- cohens_d
        }
        
        # 存入列表
        results_list[[counter]] <- temp_results
        counter <- counter + 1
      }
    }
  }
  print(paste('完成数据集', i, '处理'))
}

# 生成最终数据框
results <- do.call(rbind, lapply(results_list, as.data.frame))

# 输出数据到 CSV
write.csv(results, "Processed_Data_Matching.csv", row.names = FALSE)

print("数据处理完成，已导出 Processed_Data_Matching.csv")

```

## Pic1
```{r}
library(ggplot2)
library(dplyr)
library(tidyr)
library(Hmisc)
library(plyr)
library(RColorBrewer)
library(reshape2)

# 读取数据
data <- read.csv("Processed_Data.csv")

# 重新命名列以匹配需求
colnames(data) <- c("rt_self", "rt_close", "rt_stranger", "rt_non_person", "rt_acquaintance", 
                    "cohens_d_self_close", "cohens_d_self_stranger", "cohens_d_self_non_person", "cohens_d_self_acquaintance")

# 计算 RT 差值
data$SA_RT <- data$rt_self - data$rt_acquaintance
data$SC_RT <- data$rt_self - data$rt_close
data$SS_RT <- data$rt_self - data$rt_stranger
data$SN_RT <- data$rt_self - data$rt_non_person

# 定义 geom_flat_violin
"%||%" <- function(a, b) { if (!is.null(a)) a else b }

geom_flat_violin <- function(mapping = NULL, data = NULL, stat = "ydensity",
                             position = "dodge", trim = TRUE, scale = "area",
                             show.legend = NA, inherit.aes = TRUE, ...) {
  layer(
    data = data,
    mapping = mapping,
    stat = stat,
    geom = GeomFlatViolin,
    position = position,
    show.legend = show.legend,
    inherit.aes = inherit.aes,
    params = list(
      trim = trim,
      scale = scale,
      ...
    )
  )
}

GeomFlatViolin <- ggproto("GeomFlatViolin", Geom,
          setup_data = function(data, params) {
            data$width <- data$width %||%
              params$width %||% (resolution(data$x, FALSE) * 0.9)
            
            data %>%
              group_by(group) %>%
              mutate(ymin = min(y),
                     ymax = max(y),
                     xmin = x,
                     xmax = x + width / 2)
          },
          draw_group = function(data, panel_scales, coord) {
            data <- transform(data, xminv = x,
                              xmaxv = x + violinwidth * (xmax - x))
            newdata <- rbind(plyr::arrange(transform(data, x = xminv), y),
                             plyr::arrange(transform(data, x = xmaxv), -y))
            newdata <- rbind(newdata, newdata[1,])
            ggplot2:::ggname("geom_flat_violin", GeomPolygon$draw_panel(newdata, panel_scales, coord))
          },
          draw_key = draw_key_polygon,
          default_aes = aes(weight = 1, colour = "grey20", fill = "white", size = 0.5,
                            alpha = NA, linetype = "solid"),
          required_aes = c("x", "y")
)

raincloud_theme <- theme(
  text = element_text(size = 10),
  axis.title.x = element_text(size = 16),
  axis.title.y = element_text(size = 16),
  axis.text = element_text(size = 14),
  axis.text.x = element_text(angle = 45, vjust = 0.5),
  legend.title = element_text(size = 16),
  legend.text = element_text(size = 16),
  legend.position = "right",
  plot.title = element_text(lineheight = .8, face = "bold", size = 16),
  panel.border = element_blank(),
  panel.grid.minor = element_blank(),
  panel.grid.major = element_blank(),
  axis.line.x = element_line(colour = 'black', size = 0.5, linetype = 'solid'),
  axis.line.y = element_line(colour = 'black', size = 0.5, linetype = 'solid')
)

# 画图函数
generate_plot <- function(x_var, y_var, x_label, y_label, title) {
  ggplot(data, aes_string(x = x_var, y = y_var)) +
    geom_point(color = "blue", alpha = 0.6) +
    geom_boxplot(width = 0.2, outlier.shape = NA) +
    geom_flat_violin(aes(fill = ..density..), scale = "width", trim = FALSE, alpha = 0.5) +
    geom_smooth(method = "lm", color = "red", se = TRUE) +
    theme_minimal() +
    raincloud_theme +
    labs(x = x_label, y = y_label, title = title)
}

# 绘制四个图
p1.1 <- generate_plot("SA_RT", "cohens_d_self_acquaintance", "SA_RT", "Cohen's d (Self - Acquaintance)", "P1.1: RT vs. Cohen's d (Self - Acquaintance)")
p1.2 <- generate_plot("SC_RT", "cohens_d_self_close", "SC_RT", "Cohen's d (Self - Close)", "P1.2: RT vs. Cohen's d (Self - Close)")
p1.3 <- generate_plot("SS_RT", "cohens_d_self_stranger", "SS_RT", "Cohen's d (Self - Stranger)", "P1.3: RT vs. Cohen's d (Self - Stranger)")
p1.4 <- generate_plot("SN_RT", "cohens_d_self_non_person", "SN_RT", "Cohen's d (Self - Non-Person)", "P1.4: RT vs. Cohen's d (Self - Non-Person)")

# 显示所有图形
library(gridExtra)
grid.arrange(p1.1, p1.2, p1.3, p1.4, ncol = 2)

```

## SDF
```{r}
# 加载必要的库
library(dplyr)
library(readr)

# 设置数据路径
dataPath <- "../1_Clean_Data"
data_files <- list.files(path = dataPath, pattern = "\\.csv$", full.names = TRUE, recursive = TRUE)

# 读取并合并数据
df_combined <- lapply(data_files, function(file) {
  df <- read_csv(file)
  df$SourceFile <- basename(file)  # 添加文件来源信息
  df
}) %>% bind_rows()

# 确保数据包含所需变量
required_vars <- c("RT_ms", "Standarlized_Identity", "Subject", "Matching")
df_combined <- df_combined %>% select(all_of(required_vars))

# 过滤异常反应时（RT < 10ms 或 RT > 5000ms）
df_combined <- df_combined %>%
  filter(RT_ms > 10 & RT_ms < 5000)

# 按 Subject 和试次顺序排序（假设数据是按出现顺序排列的）
df_combined <- df_combined %>%
  group_by(Subject, Matching) %>%
  arrange(Subject, Matching, .by_group = TRUE) %>%
  mutate(
    RT_lag1 = lag(RT_ms, 1),
    RT_lag2 = lag(RT_ms, 2),
    RT_lag3 = lag(RT_ms, 3),
    RT_lag4 = lag(RT_ms, 4),
    RT_lag5 = lag(RT_ms, 5)
  ) %>%
  ungroup()

# 查看数据结构
glimpse(df_combined)

# 计算当前 RT 和滞后 RT 之间的相关性
cor_results <- df_combined %>%
  summarise(
    cor_lag1 = cor(RT_ms, RT_lag1, use = "complete.obs"),
    cor_lag2 = cor(RT_ms, RT_lag2, use = "complete.obs"),
    cor_lag3 = cor(RT_ms, RT_lag3, use = "complete.obs"),
    cor_lag4 = cor(RT_ms, RT_lag4, use = "complete.obs"),
    cor_lag5 = cor(RT_ms, RT_lag5, use = "complete.obs")
  )

# 打印相关性结果
print(cor_results)

# 进行线性回归分析，检查滞后 RT 是否预测当前 RT
lm_model <- lm(RT_ms ~ RT_lag1 + RT_lag2 + RT_lag3 + RT_lag4 + RT_lag5, data = df_combined)
summary(lm_model)

```

```{r}
library(dplyr)
library(readr)

## 设置数据路径
dataPath <- "../1_Clean_Data"
data_files <- list.files(path = dataPath, pattern = "\\.csv$", full.names = TRUE, recursive = TRUE)

## 预分配存储变量（列表存储数据）
results_list <- list()

## 计数器
counter <- 1

## 读取 CSV 文件并处理数据
for (i in seq_along(data_files)) {
  Data <- read_csv(data_files[i], show_col_types = FALSE) %>%
    mutate(across(where(is.character), as.character))  # 确保字符变量类型一致
  
  # 确保数据包含所需变量
  if (all(c("RT_ms", "ACC","Standarlized_Identity", "Subject", "Matching","Block","Trial") %in% names(Data))) {
    
    # 生成唯一标识每篇文章的 Subject ID
    Data <- Data %>%
      mutate(Subject = paste0(basename(data_files[i]), "_", Subject))
    
    # 过滤 RT 在合理范围内的行
    Data <- Data %>%
      filter(RT_ms > 10 & RT_ms < 5000)  # 过滤异常值

    # **存入列表**
    results_list[[counter]] <- Data %>%
      select(Subject, Block, Trial, Matching, Standarlized_Identity, RT_ms, ACC)  # 仅保留所需列
    
    counter <- counter + 1
  }
  print(paste('完成数据集', i, '处理'))
}

# **合并所有数据**
results <- bind_rows(results_list)

# **检查合并后的数据**
print("数据处理完成，已存入 `results` 变量")
# 输出数据到 CSV
write.csv(results, "Processed_Data.csv", row.names = FALSE)
```
# Read csv
```{r}
library(dplyr)
library(readr)

## 设置数据路径
dataPath <- "../1_Clean_Data"
data_files <- list.files(path = dataPath, pattern = "\\.csv$", full.names = TRUE, recursive = TRUE)

## 预分配存储变量（列表存储数据）
results_list <- list()

## 计数器
counter <- 1

## 读取 CSV 文件并处理数据
for (i in seq_along(data_files)) {
  file_name <- basename(data_files[i])  # 提取文件名（假设文件名代表文章名称）
  
  Data <- read_csv(data_files[i], show_col_types = FALSE) %>%
    mutate(across(where(is.character), as.character))  # 确保字符变量类型一致
  
  # 确保数据包含所需变量
  if (all(c("RT_ms", "ACC", "Standarlized_Identity", "Subject", "Matching", "Block", "Trial") %in% names(Data))) {
    
    # 生成唯一标识每篇文章的 Subject ID，并添加 Source 变量
    Data <- Data %>%
      mutate(
        Subject = paste0(file_name, "_", Subject),
        Source = file_name  # **新增变量，标记来源文章**
      )
    
    # 过滤 RT 在合理范围内的行
    Data <- Data %>%
      filter(RT_ms > 10 & RT_ms < 5000)  # 过滤异常值

    # **存入列表**
    results_list[[counter]] <- Data %>%
      select(Source, Subject, Block, Trial, Matching, Standarlized_Identity, RT_ms, ACC)  # **保留 Source 变量**
    
    counter <- counter + 1
  }
  print(paste('完成数据集', i, '处理'))
}

# **合并所有数据**
results <- bind_rows(results_list)

# **检查合并后的数据**
print("数据处理完成，已存入 `results` 变量")

# **输出数据到 CSV**
write.csv(results, "Processed_Data.csv", row.names = FALSE)
```
# Copute SDE
```{r}
library(dplyr)
library(lme4)  # 用于LMM
library(lmerTest)  # 提供p值（可选）

# 假设你的数据已加载到 `results` 中
# 如果没有，先运行你的原始代码生成 `results`

# 1. 按Subject和Block排序，并生成lag变量
data_seq <- results %>%
  arrange(Subject, Block, Trial) %>%
  group_by(Subject, Block) %>%  # 在每个Subject和Block内操作
  mutate(
    Lag1_Identity = lag(Standarlized_Identity, 1),  # 前1次
    Lag2_Identity = lag(Standarlized_Identity, 2),  # 前2次
    Lag3_Identity = lag(Standarlized_Identity, 3),  # 前3次
    Lag4_Identity = lag(Standarlized_Identity, 4),  # 前4次
    Lag5_Identity = lag(Standarlized_Identity, 5),  # 前5次
    Lag6_Identity = lag(Standarlized_Identity, 6),  # 前6次
    Lag7_Identity = lag(Standarlized_Identity, 7)   # 前7次
  ) %>%
  ungroup()

# 2. 移除开头没有完整lag数据的行
data_seq_clean <- data_seq %>%
  filter(!is.na(Lag7_Identity))  # 确保所有lag变量都非NA

# 3. 检查数据
print("序列位置效应数据已生成，以下是前几行：")
print(head(data_seq_clean))

# 4. 建立LMM模型分析RT
# 固定效应：当前Identity + 前7次Identity
# 随机效应：Subject
rt_lmm <- lmer(RT_ms ~ Standarlized_Identity + Lag1_Identity + Lag2_Identity + 
               Lag3_Identity + Lag4_Identity + Lag5_Identity + Lag6_Identity + 
               Lag7_Identity + (1 | Subject), 
               data = data_seq_clean)

# 5. 查看模型结果
summary(rt_lmm)

# 6. （可选）保存模型结果到文件
sink("RT_LMM_Summary.txt")
print(summary(rt_lmm))
sink()

# 7. 保存处理后的数据
write.csv(data_seq_clean, "Sequence_Effect_Data.csv", row.names = FALSE)
```


